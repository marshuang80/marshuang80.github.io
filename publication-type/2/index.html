<!doctype html><!-- This site was created with Wowchemy. https://www.wowchemy.com --><!-- Last Published: January 29, 2023 --><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.7.0 for Hugo"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=B612+Mono&family=B612:wght@400;700&family=Jura:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=B612+Mono&family=B612:wght@400;700&family=Jura:wght@400;700&display=swap" media=print onload='this.media="all"'><link rel=stylesheet href=/css/vendor-bundle.min.16f785cdb553c8c4431db6775122af35.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.2/css/academicons.min.css integrity="sha512-KlJCpRsLf+KKu2VQa5vmRuClRFjxc5lXO03ixZt82HZUk41+1I0bD8KBSA0fY290ayMfWYI9udIqeOWSu1/uZg==" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.af55899d8b924748b901d470aa7b0bd6.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><meta name=author content="Mars (Shih-Cheng) Huang"><meta name=description content="A highly-customizable Hugo academic resume theme powered by Wowchemy website builder."><link rel=alternate hreflang=en-us href=https://marshuang80.github.io/publication-type/2/><link rel=canonical href=https://marshuang80.github.io/publication-type/2/><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hu687e722fa5af903774003502d32d2ddb_42108_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu687e722fa5af903774003502d32d2ddb_42108_180x180_fill_lanczos_center_3.png><meta name=theme-color content="#1565c0"><meta property="twitter:card" content="summary"><meta property="twitter:site" content="@wowchemy"><meta property="twitter:creator" content="@wowchemy"><meta property="twitter:image" content="https://marshuang80.github.io/media/icon_hu687e722fa5af903774003502d32d2ddb_42108_512x512_fill_lanczos_center_3.png"><meta property="og:site_name" content="Mars Huang"><meta property="og:url" content="https://marshuang80.github.io/publication-type/2/"><meta property="og:title" content="2 | Mars Huang"><meta property="og:description" content="A highly-customizable Hugo academic resume theme powered by Wowchemy website builder."><meta property="og:image" content="https://marshuang80.github.io/media/icon_hu687e722fa5af903774003502d32d2ddb_42108_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us"><meta property="og:updated_time" content="2023-01-02T00:00:00+00:00"><link rel=alternate href=/publication-type/2/index.xml type=application/rss+xml title="Mars Huang"><title>2 | Mars Huang</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper><script src=/js/wowchemy-init.min.ec9d49ca50e4b80bdb08f0417a28ed84.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class="page-header header--fixed"><header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Mars Huang</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Mars Huang</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about><span>About</span></a></li><li class=nav-item><a class=nav-link href=/#featured><span>Featured</span></a></li><li class=nav-item><a class=nav-link href=/#publications><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/#experiences><span>Experiences</span></a></li><li class=nav-item><a class=nav-link href=/#photos><span>Photography</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class="nav-item d-none d-lg-inline-flex"><a class=nav-link href=https://twitter.com/MarsScHuang data-toggle=tooltip data-placement=bottom title="Follow me on Twitter" target=_blank rel=noopener aria-label="Follow me on Twitter"><i class="fab fa-twitter" aria-hidden=true></i></a></li><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></header></div><div class=page-body><div class="universal-wrapper pt-3"><h1>2</h1></div><div class=universal-wrapper><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/ssl-federated/>Self-supervised learning for medical image classification: a systematic review and implementation guidelines</a></div><a href=/publication/ssl-federated/ class=summary-link><div class=article-style>In this paper, we present a robust and label-efficient self-supervised FL framework for medical image analysis. Our method introduces a novel Transformer-based self-supervised pre-training paradigm that pre-trains models directly on decentralized target task datasets using masked image modeling, to facilitate more robust representation learning on heterogeneous data and effective knowledge transfer to downstream models.</div></a><div class="stream-meta article-metadata"><div><span>Rui Yan</span>, <span>Liangqiong Qu</span>, <span>Qingyue Wei</span>, <span class=author-highlighted>Mars (Shih-Cheng) Huang</span>, <span>Liyue Shen</span>, <span>Daniel Rubin</span>, <span>Lei Xing</span>, <span>Yuyin Zhou</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10004993" target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/ssl-federated/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/rui-yan/SSL-FL target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/https://doi.org/10.1109/TMI.2022.3233574 target=_blank rel=noopener>DOI</a></div></div><div class=ml-3><a href=/publication/ssl-federated/><img src=/publication/ssl-federated/featured_hu1dd1a531de43f358ed4aa0ac270602d2_430452_150x0_resize_q75_h2_lanczos_3.webp height=52 width=150 alt="Self-supervised learning for medical image classification: a systematic review and implementation guidelines" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/ssl/>Self-supervised learning for medical image classification: a systematic review and implementation guidelines</a></div><a href=/publication/ssl/ class=summary-link><div class=article-style>In this review, we provide consistent descriptions of different self-supervised learning strategies and compose a systematic review of papers published between 2012 and 2022 on PubMed, Scopus, and ArXiv that applied self-supervised learning to medical imaging classification. With this comprehensive effort, we synthesize the collective knowledge of prior work and provide implementation guidelines for future researchers interested in applying self-supervised learning to their development of medical imaging classification models.</div></a><div class="stream-meta article-metadata"><div><span class=author-highlighted>Mars (Shih-Cheng) Huang</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span>Anuj Pareek</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span>Malte Jensen</span>, <span>Matthew P. Lungren</span>, <span>Serena Yeung</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span>Akshay S. Chaudhari</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/publication/ssl/conference-paper.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/ssl/cite.bib>Cite</a></div></div><div class=ml-3><a href=/publication/ssl/><img src=/publication/ssl/featured_hu7c5ff2c1e9ad51f00bd6875a80ad2826_468879_150x0_resize_q75_h2_lanczos_3.webp height=244 width=150 alt="Self-supervised learning for medical image classification: a systematic review and implementation guidelines" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/infectious/>Developing medical imaging AI for emerging infectious diseases</a></div><a href=/publication/infectious/ class=summary-link><div class=article-style>In this review, we provide an evidence-based roadmap for how machine learning technologies in medical imaging can be used to battle ongoing and future pandemics. Specifically, we focus in each section on the four most pressing issues, namely - needfinding, dataset curation, model development and subsequent evaluation, and post-deployment considerations.</div></a><div class="stream-meta article-metadata"><div><span class=author-highlighted>Mars (Shih-Cheng) Huang</span>, <span>Akshay S. Chaudhari</span>, <span>Curtis P. Langlotz</span>, <span>Nigam Shah</span>, <span>Serena Yeung</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span>Matthew P. Lungren</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://www.nature.com/articles/s41467-022-34234-4 target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/infectious/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/https://doi.org/10.1038/s41467-022-34234-4 target=_blank rel=noopener>DOI</a></div></div><div class=ml-3><a href=/publication/infectious/><img src=/publication/infectious/featured_hu7e55216efe0083e82003e78abbe6d877_128440_150x0_resize_q75_h2_lanczos.webp height=91 width=150 alt="Developing medical imaging AI for emerging infectious diseases" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/ai_race/>AI recognition of patient race in medical imaging: a modelling study</a></div><a href=/publication/ai_race/ class=summary-link><div class=article-style>Previous studies in medical imaging have shown disparate abilities of artificial intelligence (AI) to detect a person&rsquo;s race, yet there is no known correlation for race on medical imaging that would be obvious to human experts when interpreting the images. We aimed to conduct a comprehensive evaluation of the ability of AI to recognise a patient&rsquo;s racial identity from medical images.</div></a><div class="stream-meta article-metadata"><div><span>Judy Wawira Gichoya</span>, <span>Imon Banerjee</span>, <span>Ananth Reddy Bhimireddy</span>, <span>John L Burns</span>, <span>Leo Anthony Celi</span>, <span>Li-Ching Chen</span>, <span>Ramon Correa</span>, <span>Natalie Dullerud</span>, <span>Marzyeh Ghassemi</span>, <span class=author-highlighted>Mars (Shih-Cheng) Huang</span>, <span>Po-Chih Kuo</span>, <span>Matthew P Lungren</span>, <span>Lyle J Palmer</span>, <span>Brandon J Price</span>, <span>Saptarshi Purkayastha</span>, <span>Ayis T Pyrros</span>, <span>Lauren Oakden-Rayner</span>, <span>Chima Okechukwu</span>, <span>Laleh Seyyed-Kalantari</span>, <span>Hari Trivedi</span>, <span>Ryan Wang</span>, <span>Zachary Zaiman</span>, <span>Haoran Zhang</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://www.sciencedirect.com/science/article/pii/S2589750022000632 target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/ai_race/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/Emory-HITI/AI-Vengers target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/https://doi.org/10.1016/S2589-7500%2822%2900063-2 target=_blank rel=noopener>DOI</a></div></div><div class=ml-3><a href=/publication/ai_race/><img src=/publication/ai_race/featured_hu73cf89195550bc7e65d532ecd5888fc8_393536_150x0_resize_q75_h2_lanczos_3.webp height=71 width=150 alt="AI recognition of patient race in medical imaging: a modelling study" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/prostate_multimodal/>Prostate cancer therapy personalization via multi-modal deep learning on randomized phase III clinical trials</a></div><a href=/publication/prostate_multimodal/ class=summary-link><div class=article-style>In this study, we demonstrate prostate cancer therapy personalization by predicting long-term, clinically relevant outcomes using a multimodal deep learning architecture and train models using clinical data and digital histopathology from prostate biopsies. We train and validate models using five phase III randomized trials conducted across hundreds of clinical centers. Compared to the most common risk-stratification tool—risk groups developed by the National Cancer Center Network (NCCN)—our models have superior discriminatory performance across all endpoints, ranging from 9.2% to 14.6% relative improvement in a held-out validation set.</div></a><div class="stream-meta article-metadata"><div><span>Andre Esteva</span>, <span>Jean Feng</span>, <span>Douwe van der Wal</span>, <span class=author-highlighted>Mars (Shih-Cheng) Huang</span>, <span>Jeffry P Simko</span>, <span>Sandy DeVries</span>, <span>Emmalyn Chen</span>, <span>Edward M Schaeffer</span>, <span>Todd M Morgan</span>, <span>Yilun Sun</span>, <span>Amirata Ghorbani</span>, <span>Nikhil Naik</span>, <span>Dhruv Nathawani</span>, <span>Richard Socher</span>, <span>Jeff M Michalski</span>, <span>Mack Roach III</span>, <span>Thomas M Pisansky</span>, <span>Jedidiah M Monson</span>, <span>Farah Naz</span>, <span>James Wallace</span>, <span>Michelle J Ferguson</span>, <span>Jean-Paul Bahary</span>, <span>James Zou</span>, <span>Matthew Lungren</span>, <span>Serena Yeung</span>, <span>Ashley E Ross</span>, <span>Howard M Sandler</span>, <span>Phuoc T Tran</span>, <span>Daniel E Spratt</span>, <span>Stephanie Pugh</span>, <span>Felix Y Feng</span>, <span>Osama Mohamad</span>, <span>NRG Prostate Cancer AI Consortium</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://www.nature.com/articles/s41746-022-00613-w target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/prostate_multimodal/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/https://doi.org/10.1038/s41746-022-00613-w target=_blank rel=noopener>DOI</a></div></div><div class=ml-3><a href=/publication/prostate_multimodal/><img src=/publication/prostate_multimodal/featured_hu16f6646f446ccfd4e904ae48d07608f2_85684_150x0_resize_q75_h2_lanczos.webp height=103 width=150 alt="Prostate cancer therapy personalization via multi-modal deep learning on randomized phase III clinical trials" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/prostate_multimodal_oncology/>Development and validation of a prognostic AI biomarker using multi-modal deep learning with digital histopathology in localized prostate cancer on NRG Oncology phase III clinical trials.</a></div><a href=/publication/prostate_multimodal_oncology/ class=summary-link><div class=article-style>Prognostication in localized prostate cancer is reliant on non-specific tools, an issue that leads to the over- and under-treatment of patients. Various tissue-based molecular biomarkers have attempted to fill this unmet need, but most lack prospective randomized trial validation. Herein, we train and validate prognostic biomarkers in localized prostate cancer using five phase III randomized trials, by leveraging multi-modal deep learning on digital histopathology.</div></a><div class="stream-meta article-metadata"><div><span>Andre Esteva</span>, <span>Jean Feng</span>, <span class=author-highlighted>Mars (Shih-Cheng) Huang</span>, <span>Douwe van der Wal</span>, <span>Jeffry Simko</span>, <span>Sandy DeVries</span>, <span>Emmalyn Chen</span>, <span>Edward M Schaeffer</span>, <span>Todd Matthew Morgan</span>, <span>Jedidiah Mercer Monson</span>, <span>Farah Naz</span>, <span>James Wallace</span>, <span>Michelle J Ferguson</span>, <span>Jean-Paul Bahary</span>, <span>Howard M Sandler</span>, <span>Phuoc T Tran</span>, <span>Daniel Eidelberg Spratt</span>, <span>Stephanie L Pugh</span>, <span>Felix Y Feng</span>, <span>Osama Mohamad</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://ascopubs.org/doi/abs/10.1200/JCO.2022.40.6_suppl.222 target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/prostate_multimodal_oncology/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/https://doi.org/10.1200/JCO.2022.40.6_suppl.222 target=_blank rel=noopener>DOI</a></div></div><div class=ml-3><a href=/publication/prostate_multimodal_oncology/><img src=/publication/prostate_multimodal_oncology/featured_huc69a04f07d6347557c7de2c054e7842f_93544_150x0_resize_q75_h2_lanczos.webp height=73 width=150 alt="Development and validation of a prognostic AI biomarker using multi-modal deep learning with digital histopathology in localized prostate cancer on NRG Oncology phase III clinical trials." loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/lung_segmentation/>Automatic lung nodule segmentation and intra-nodular heterogeneity image generation</a></div><a href=/publication/lung_segmentation/ class=summary-link><div class=article-style>In this study, we propose an end-to-end architecture to perform fully automated segmentation of multiple types of lung nodules and generate intra-nodular heterogeneity images for clinical use.</div></a><div class="stream-meta article-metadata"><div><span>Jiangdian Song</span>, <span class=author-highlighted>Mars (Shih-Cheng) Huang</span>, <span>Brendan Kelly</span>, <span>Guanqun Liao</span>, <span>Jing-yun Shi</span>, <span>Ning Wu</span>, <span>Weimin Li</span>, <span>Zaiyi Liu</span>, <span>Lei Cui</span>, <span>Matthew P Lungren</span>, <span>Michael Moseley</span>, <span>Peng Gao</span>, <span>Jie Tian</span>, <span>Kristen Yeom</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://ieeexplore.ieee.org/abstract/document/9652062 target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/lung_segmentation/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/https://doi.org/10.1109/JBHI.2021.3135647 target=_blank rel=noopener>DOI</a></div></div><div class=ml-3><a href=/publication/lung_segmentation/><img src=/publication/lung_segmentation/featured_hu1b20a30fcdaf73fef6427c757eab0634_795856_150x0_resize_q75_h2_lanczos_3.webp height=115 width=150 alt="Automatic lung nodule segmentation and intra-nodular heterogeneity image generation" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/radfusion/>RadFusion: Benchmarking Performance and Fairness for Multimodal Pulmonary Embolism Detection from CT and EHR</a></div><a href=/publication/radfusion/ class=summary-link><div class=article-style>We present RadFusion, a multimodal, benchmark dataset of 1794 patients with corresponding EHR data and high-resolution computed tomography (CT) scans labeled for pulmonary embolisms. We evaluate several representative multimodal fusion models and benchmark their fairness properties across protected subgroups, e.g., gender, race/ethnicity, age. Our results suggest that integrating imaging and EHR data can improve classification performance and robustness without introducing large disparities in the true positive rate between population groups.</div></a><div class="stream-meta article-metadata"><div><span>Yuyin Zhou</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span class=author-highlighted>Mars (Shih-Cheng) Huang</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span>Jason Alan Fries</span>, <span>Alaa Youssef</span>, <span>Timothy J. Amrhein</span>, <span>Marcello Chang</span>, <span>Imon Banerjee</span>, <span>Daniel Rubin</span>, <span>Lei Xing</span>, <span>Nigam Shah</span>, <span>Matthew P. Lungren</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2111.11665 target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/radfusion/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/https://doi.org/10.48550/arXiv.2111.11665 target=_blank rel=noopener>DOI</a></div></div><div class=ml-3></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/pe_multimodal/>Multimodal fusion with deep neural networks for leveraging CT imaging and electronic health record: a case-study in pulmonary embolism detection</a></div><a href=/publication/pe_multimodal/ class=summary-link><div class=article-style>In this study, we developed and compared different multimodal fusion model architectures that are capable of utilizing both pixel data from volumetric Computed Tomography Pulmonary Angiography scans and clinical patient data from the EMR to automatically classify Pulmonary Embolism (PE) cases.</div></a><div class="stream-meta article-metadata"><div><span class=author-highlighted>Mars (Shih-Cheng) Huang</span>, <span>Anuj Pareek</span>, <span>Roham Zamanian</span>, <span>Imon Banerjee</span>, <span>Matthew P. Lungren</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://www.nature.com/articles/s41598-020-78888-w target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/pe_multimodal/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/https://doi.org/10.1038/s41598-020-78888-w target=_blank rel=noopener>DOI</a></div></div><div class=ml-3><a href=/publication/pe_multimodal/><img src=/publication/pe_multimodal/featured_hubce7dd814e102ff34d8eed5425676021_144672_150x0_resize_q75_h2_lanczos.webp height=55 width=150 alt="Multimodal fusion with deep neural networks for leveraging CT imaging and electronic health record: a case-study in pulmonary embolism detection" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/bgv/>Biomedical Graph Visualizer for Identifying Drug Candidates</a></div><a href=/publication/bgv/ class=summary-link><div class=article-style>We built a computational knowledge graph focused on biomedical concepts related to drug discovery, designed visualization tools that allow users to explore complex relationships among entities in the graph, and served these tools through a free and user-friendly web interface. We show that users can conduct complex analyses with relative ease and that our knowledge graph and algorithms recover approved repurposed drugs.</div></a><div class="stream-meta article-metadata"><div><span>Ashton Teng</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span>Blanca Villanueva</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span>Derek Jow</span>, <span class=author-highlighted>Mars (Shih-Cheng) Huang</span>, <span>Samantha N Piekos</span>, <span>Russ B Altman</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://www.biorxiv.org/content/10.1101/2020.11.27.368811v1.abstract target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/bgv/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/https://doi.org/10.1101/2020.11.27.368811 target=_blank rel=noopener>DOI</a></div></div><div class=ml-3></div></div><nav class=mt-1><ul class="pagination justify-content-center"><li class=page-item><a class=page-link href=/publication-type/2/page/2/>&#187;</a></li></ul></nav></div></div><div class=page-footer><div class=container><footer class=site-footer><p class="powered-by copyright-license-text">© 2023 Me. This work is licensed under <a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank>CC BY NC ND 4.0</a></p><p class="powered-by footer-license-icons"><a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank aria-label="Creative Commons"><i class="fab fa-creative-commons fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-by fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nc fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nd fa-2x" aria-hidden=true></i></a></p><p class=powered-by>Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — the free, <a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><script src=/js/vendor-bundle.min.d26509351aa0ff874abbee824e982e9b.js></script>
<script id=search-hit-fuse-template type=text/x-template>
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script>
<script id=page-data type=application/json>{"use_headroom":true}</script><script src=/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js type=module></script>
<script src=/en/js/wowchemy.min.e8ee06ba8371980ffde659871dd593b0.js></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js type=module></script></body></html>