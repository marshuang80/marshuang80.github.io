[{"authors":null,"categories":null,"content":"Hi there - I am a PhD candidate in Biomedical Informatics at Stanford University, studying artificial intelligence and clinical informatics. I am currently advised by Serena Yeung, Curtis Langlotz, Nigam Shah and previously by Matthew P. Lungren. I am affiliated with Stanford’s MARVL lab and AIMI Center.\nMy research focuses on the intersection of multimodal and self-supervised learning, and the application of these methods to improve healthcare.\n","date":1672704e3,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1672704e3,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Hi there - I am a PhD candidate in Biomedical Informatics at Stanford University, studying artificial intelligence and clinical informatics. I am currently advised by Serena Yeung, Curtis Langlotz, Nigam Shah and previously by Matthew P.","tags":null,"title":"Mars (Shih-Cheng) Huang","type":"authors"},{"authors":["Yuhui Zhang","Jeff Z HaoChen","Mars (Shih-Cheng) Huang","Kuan-Chieh Wang","James Zou","Serena Yeung"],"categories":null,"content":"","date":1672704e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672704e3,"objectID":"50efda0b5e8b63727369ffbe4134b1db","permalink":"https://marshuang80.github.io/publication/dr-ml/","publishdate":"2023-01-03T00:00:00Z","relpermalink":"/publication/dr-ml/","section":"publication","summary":"The traditional process of diagnosing model behaviors in deployment settings involves labor-intensive data acquisition and annotation. Our proposed method, DrML, can discover high-error data slices, identify influential attributes and further rectify undesirable model behaviors, without requiring any visual data. Through a combination of theoretical explanation and empirical verification, we present conditions under which classifiers trained on embeddings from one modality can be equivalently applied to embeddings from another modality.","tags":[],"title":"DrML: Diagnosing and Rectifying Vision Models using Language","type":"publication"},{"authors":["Rui Yan","Liangqiong Qu","Qingyue Wei","Mars (Shih-Cheng) Huang","Liyue Shen","Daniel Rubin","Lei Xing","Yuyin Zhou"],"categories":null,"content":"","date":1672617600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672617600,"objectID":"f0eb799c1d8fc72a0e414a7216dc6d5c","permalink":"https://marshuang80.github.io/publication/ssl-federated/","publishdate":"2023-01-02T00:00:00Z","relpermalink":"/publication/ssl-federated/","section":"publication","summary":"In this paper, we present a robust and label-efficient self-supervised FL framework for medical image analysis. Our method introduces a novel Transformer-based self-supervised pre-training paradigm that pre-trains models directly on decentralized target task datasets using masked image modeling, to facilitate more robust representation learning on heterogeneous data and effective knowledge transfer to downstream models.","tags":[],"title":"Self-supervised learning for medical image classification: a systematic review and implementation guidelines","type":"publication"},{"authors":["Mars (Shih-Cheng) Huang","Anuj Pareek","Malte Jensen","Matthew P. Lungren","Serena Yeung","Akshay S. Chaudhari"],"categories":null,"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"f1059c27d50f0d89452c76339139ed1e","permalink":"https://marshuang80.github.io/publication/ssl/","publishdate":"2023-01-01T00:00:00Z","relpermalink":"/publication/ssl/","section":"publication","summary":"In this review, we provide consistent descriptions of different self-supervised learning strategies and compose a systematic review of papers published between 2012 and 2022 on PubMed, Scopus, and ArXiv that applied self-supervised learning to medical imaging classification. With this comprehensive effort, we synthesize the collective knowledge of prior work and provide implementation guidelines for future researchers interested in applying self-supervised learning to their development of medical imaging classification models.","tags":[],"title":"Self-supervised learning for medical image classification: a systematic review and implementation guidelines","type":"publication"},{"authors":["Yuhui Zhang","Mars (Shih-Cheng) Huang","Zhengping Zhou,","Matthew P. Lungren,","Serena Yeung"],"categories":null,"content":"","date":166968e4,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":166968e4,"objectID":"5bcb6bd83d53db47118802748a846e78","permalink":"https://marshuang80.github.io/publication/transformers-segmentation/","publishdate":"2022-11-29T00:00:00Z","relpermalink":"/publication/transformers-segmentation/","section":"publication","summary":"In this work, we use a simple yet effective weight inflation strategy to adapt pre-trained Transformers from 2D to 3D, retaining the benefit of both transfer learning and depth information. We further investigate the effectiveness of transfer from different pre-training sources and objectives. Our approach achieves state-of-the-art performances across a broad range of 3D medical image datasets.","tags":[],"title":"Adapting pre-trained vision transformers from 2D to 3D through weight inflation improves medical image segmentation","type":"publication"},{"authors":["Mars (Shih-Cheng) Huang","Akshay S. Chaudhari","Curtis P. Langlotz","Nigam Shah","Serena Yeung","Matthew P. Lungren"],"categories":null,"content":"","date":1668729600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668729600,"objectID":"3096200c7de3d492810892481c600ff5","permalink":"https://marshuang80.github.io/publication/infectious/","publishdate":"2022-11-18T00:00:00Z","relpermalink":"/publication/infectious/","section":"publication","summary":"In this review, we provide an evidence-based roadmap for how machine learning technologies in medical imaging can be used to battle ongoing and future pandemics. Specifically, we focus in each section on the four most pressing issues, namely - needfinding, dataset curation, model development and subsequent evaluation, and post-deployment considerations.","tags":[],"title":"Developing medical imaging AI for emerging infectious diseases","type":"publication"},{"authors":["Judy Wawira Gichoya","Imon Banerjee","Ananth Reddy Bhimireddy","John L Burns","Leo Anthony Celi","Li-Ching Chen","Ramon Correa","Natalie Dullerud","Marzyeh Ghassemi","Mars (Shih-Cheng) Huang","Po-Chih Kuo","Matthew P Lungren","Lyle J Palmer","Brandon J Price","Saptarshi Purkayastha","Ayis T Pyrros","Lauren Oakden-Rayner","Chima Okechukwu","Laleh Seyyed-Kalantari","Hari Trivedi","Ryan Wang","Zachary Zaiman","Haoran Zhang"],"categories":null,"content":"","date":1654041600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1654041600,"objectID":"903f6284599894dd955fc37faf55f99c","permalink":"https://marshuang80.github.io/publication/ai_race/","publishdate":"2022-06-01T00:00:00Z","relpermalink":"/publication/ai_race/","section":"publication","summary":"Previous studies in medical imaging have shown disparate abilities of artificial intelligence (AI) to detect a person's race, yet there is no known correlation for race on medical imaging that would be obvious to human experts when interpreting the images. We aimed to conduct a comprehensive evaluation of the ability of AI to recognise a patient's racial identity from medical images.","tags":[],"title":"AI recognition of patient race in medical imaging: a modelling study","type":"publication"},{"authors":["Andre Esteva","Jean Feng","Douwe van der Wal","Mars (Shih-Cheng) Huang","Jeffry P Simko","Sandy DeVries","Emmalyn Chen","Edward M Schaeffer","Todd M Morgan","Yilun Sun","Amirata Ghorbani","Nikhil Naik","Dhruv Nathawani","Richard Socher","Jeff M Michalski","Mack Roach III","Thomas M Pisansky","Jedidiah M Monson","Farah Naz","James Wallace","Michelle J Ferguson","Jean-Paul Bahary","James Zou","Matthew Lungren","Serena Yeung","Ashley E Ross","Howard M Sandler","Phuoc T Tran","Daniel E Spratt","Stephanie Pugh","Felix Y Feng","Osama Mohamad","NRG Prostate Cancer AI Consortium"],"categories":null,"content":"","date":1650412800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650412800,"objectID":"6c4b09ad8cf5500f99aba4278572177b","permalink":"https://marshuang80.github.io/publication/prostate_multimodal/","publishdate":"2022-04-20T00:00:00Z","relpermalink":"/publication/prostate_multimodal/","section":"publication","summary":"In this study, we demonstrate prostate cancer therapy personalization by predicting long-term, clinically relevant outcomes using a multimodal deep learning architecture and train models using clinical data and digital histopathology from prostate biopsies. We train and validate models using five phase III randomized trials conducted across hundreds of clinical centers. Compared to the most common risk-stratification tool—risk groups developed by the National Cancer Center Network (NCCN)—our models have superior discriminatory performance across all endpoints, ranging from 9.2% to 14.6% relative improvement in a held-out validation set.","tags":[],"title":"Prostate cancer therapy personalization via multi-modal deep learning on randomized phase III clinical trials","type":"publication"},{"authors":["Andre Esteva","Jean Feng","Mars (Shih-Cheng) Huang","Douwe Van der Wal","Jeffry Simko","Sandy DeVries","Emmalyn Chen","Edward M Schaeffer","Todd Matthew Morgan","Jedidiah Mercer Monson","Farah Naz","James Wallace","Michelle J Ferguson","Jean-Paul Bahary","Howard M Sandler","Phuoc T Tran","Daniel Eidelberg Spratt","Stephanie L Pugh","Felix Y Feng","Osama Mohamad"],"categories":null,"content":"","date":1645315200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645315200,"objectID":"27757d843335e16d59ae69acb0c54859","permalink":"https://marshuang80.github.io/publication/prostate_multimodal_oncology/","publishdate":"2022-02-20T00:00:00Z","relpermalink":"/publication/prostate_multimodal_oncology/","section":"publication","summary":"Prognostication in localized prostate cancer is reliant on non-specific tools, an issue that leads to the over- and under-treatment of patients. Various tissue-based molecular biomarkers have attempted to fill this unmet need, but most lack prospective randomized trial validation. Herein, we train and validate prognostic biomarkers in localized prostate cancer using five phase III randomized trials, by leveraging multi-modal deep learning on digital histopathology.","tags":[],"title":"Development and validation of a prognostic AI biomarker using multi-modal deep learning with digital histopathology in localized prostate cancer on NRG Oncology phase III clinical trials.","type":"publication"},{"authors":["Jiangdian Song","Mars (Shih-Cheng) Huang","Brendan Kelly","Guanqun Liao","Jing-yun Shi","Ning Wu","Weimin Li","Zaiyi Liu","Lei Cui","Matthew P Lungren","Michael Moseley","Peng Gao","Jie Tian","Kristen Yeom"],"categories":null,"content":"","date":1639526400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639526400,"objectID":"27140294df0502842e84de0b5902d4b5","permalink":"https://marshuang80.github.io/publication/lung_segmentation/","publishdate":"2021-12-15T00:00:00Z","relpermalink":"/publication/lung_segmentation/","section":"publication","summary":"In this study, we propose an end-to-end architecture to perform fully automated segmentation of multiple types of lung nodules and generate intra-nodular heterogeneity images for clinical use.","tags":[],"title":"Automatic lung nodule segmentation and intra-nodular heterogeneity image generation","type":"publication"},{"authors":["Yuyin Zhou","Mars (Shih-Cheng) Huang","Jason Alan Fries","Alaa Youssef","Timothy J. Amrhein","Marcello Chang","Imon Banerjee","Daniel Rubin","Lei Xing","Nigam Shah","Matthew P. Lungren"],"categories":null,"content":"","date":1637625600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1637625600,"objectID":"a45395356b2ed24b25291760085230da","permalink":"https://marshuang80.github.io/publication/radfusion/","publishdate":"2021-11-23T00:00:00Z","relpermalink":"/publication/radfusion/","section":"publication","summary":"We present RadFusion, a multimodal, benchmark dataset of 1794 patients with corresponding EHR data and high-resolution computed tomography (CT) scans labeled for pulmonary embolisms. We evaluate several representative multimodal fusion models and benchmark their fairness properties across protected subgroups, e.g., gender, race/ethnicity, age. Our results suggest that integrating imaging and EHR data can improve classification performance and robustness without introducing large disparities in the true positive rate between population groups.","tags":[],"title":"RadFusion: Benchmarking Performance and Fairness for Multimodal Pulmonary Embolism Detection from CT and EHR","type":"publication"},{"authors":["Mars (Shih-Cheng) Huang","Liyue Shen","Matthew P Lungren","Serena Yeung"],"categories":null,"content":"","date":1633910400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633910400,"objectID":"3edb11337e3f4b6c5f8b7dc85c981d99","permalink":"https://marshuang80.github.io/publication/gloria/","publishdate":"2021-10-11T00:00:00Z","relpermalink":"/publication/gloria/","section":"publication","summary":"The purpose of this work is to develop label-efficient multimodal medical imaging representations by leveraging radiology reports. Specifically, we propose an attention-based framework (GLoRIA) for learning global and local representations by contrasting image sub-regions and words in the paired report. In addition, we propose methods to leverage the learned representations for various downstream medical image recognition tasks with limited labels.","tags":[],"title":"GLoRIA: A Multimodal Global-Local Representation Learning Framework for Label-Efficient Medical Image Recognition","type":"publication"},{"authors":["Mars (Shih-Cheng) Huang","Anuj Pareek","Roham Zamanian","Imon Banerjee","Matthew P. Lungren"],"categories":null,"content":"","date":1608163200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608163200,"objectID":"0f595621300c1ac2c55f25751a9904e8","permalink":"https://marshuang80.github.io/publication/pe_multimodal/","publishdate":"2020-12-17T00:00:00Z","relpermalink":"/publication/pe_multimodal/","section":"publication","summary":"In this study, we developed and compared different multimodal fusion model architectures that are capable of utilizing both pixel data from volumetric Computed Tomography Pulmonary Angiography scans and clinical patient data from the EMR to automatically classify Pulmonary Embolism (PE) cases.","tags":[],"title":"Multimodal fusion with deep neural networks for leveraging CT imaging and electronic health record: a case-study in pulmonary embolism detection","type":"publication"},{"authors":["Ashton Teng","Blanca Villanueva","Derek Jow","Mars (Shih-Cheng) Huang","Samantha N Piekos","Russ B Altman"],"categories":null,"content":"","date":1606435200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606435200,"objectID":"3de93f66bd13ea649ef9f5fb67ce6c1e","permalink":"https://marshuang80.github.io/publication/bgv/","publishdate":"2020-11-27T00:00:00Z","relpermalink":"/publication/bgv/","section":"publication","summary":"We built a computational knowledge graph focused on biomedical concepts related to drug discovery, designed visualization tools that allow users to explore complex relationships among entities in the graph, and served these tools through a free and user-friendly web interface. We show that users can conduct complex analyses with relative ease and that our knowledge graph and algorithms recover approved repurposed drugs.","tags":[],"title":"Biomedical Graph Visualizer for Identifying Drug Candidates","type":"publication"},{"authors":["Mars (Shih-Cheng) Huang","Anuj Pareek","Saeed Seyyedi","Imon Banerjee","Matthew P. Lungren"],"categories":null,"content":"","date":1602806400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602806400,"objectID":"9de478697de67aef6cc20ebd4c5f5686","permalink":"https://marshuang80.github.io/publication/multimodal/","publishdate":"2020-10-16T00:00:00Z","relpermalink":"/publication/multimodal/","section":"publication","summary":"In this reivew, we describe different data fusion techniques that can be applied to combine medical imaging with EHR, and systematically review medical data fusion literature published between 2012 and 2020. By means of this systematic review, we present current knowledge, summarize important results and provide implementation guidelines to serve as a reference for researchers interested in the application of multimodal fusion in medical imaging.","tags":[],"title":"Fusion of medical imaging and electronic health records using deep learning: a systematic review and implementation guidelines","type":"publication"},{"authors":["Anirudh Joshi","Sabri Eyuboglu","Mars (Shih-Cheng) Huang","Jared Dunnmon","Arjun Soin","Guido Davidzon","Akshay Chaudhari","Matthew P Lungren"],"categories":null,"content":"","date":1587686400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587686400,"objectID":"c4f72f49eed870f3a2cd2727aad1422e","permalink":"https://marshuang80.github.io/publication/onconet/","publishdate":"2020-04-24T00:00:00Z","relpermalink":"/publication/onconet/","section":"publication","summary":"In this work we develop onconet, novel machine learning algorithm that assesses treatment response from a 1,954 pairs of sequential fdg pet/ct exams through weak supervision using the standard uptake values (suvmax) in associated radiology reports. onconet demonstrates an auroc of 0.86 and 0.84 on internal and external institution test sets respectively for determination of change between scans while also showing strong agreement to clinical scoring systems with a kappa score of 0.8.","tags":["Medical Images"],"title":"OncoNet: Weakly Supervised Siamese Network to automate cancer treatment response assessment between longitudinal FDG PET/CT examinations","type":"publication"},{"authors":["Mars (Shih-Cheng) Huang","Tanay Kothari","Imon Banerjee","Chris Chute","Robyn L Ball","Norah Borus","Andrew Huang","Bhavik N Patel","Pranav Rajpurkar","Jeremy Irvin","Jared Dunnmon","Joseph Bledsoe","Katie Shpanskaya","Abhay Dhaliwal","Roham Zamanian","Andrew Y Ng","Matthew P Lungren"],"categories":null,"content":"","date":1587686400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587686400,"objectID":"7979e5a246552787f83d4710a414410e","permalink":"https://marshuang80.github.io/publication/penet/","publishdate":"2020-04-24T00:00:00Z","relpermalink":"/publication/penet/","section":"publication","summary":"The PENet is a 77-layer 3D convolutional neural network (CNN) pretrained on the Kinetics-600 dataset and fine-tuned on a retrospective CTPA dataset collected from a single academic institution. The PENet model performance was evaluated in detecting PE on data from two different institutions - one as a hold-out dataset from the same institution as the training data and a second collected from an external institution to evaluate model generalizability to an unrelated population dataset. ure published between 2012 and 2020. By means of this systematic review, we present current knowledge, summarize important results and provide implementation guidelines to serve as a reference for researchers interested in the application of multimodal fusion in medical imaging.","tags":[],"title":"PENet—a scalable deep-learning model for automated diagnosis of pulmonary embolism using volumetric CT imaging","type":"publication"},{"authors":["Adam Rule","Amanda Birmingham","Cristal Zuniga","Ilkay Altintas","Mars (Shih-Cheng) Huang","Rob Knight","Niema Moshiri","Mai H. Nguyen","Sara Brin Rosenthal","Fernando Pérez","Peter W. Rose"],"categories":null,"content":"","date":1564012800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564012800,"objectID":"964872444cc3c55c779019fdbb5d707b","permalink":"https://marshuang80.github.io/publication/ten_rules/","publishdate":"2019-07-25T00:00:00Z","relpermalink":"/publication/ten_rules/","section":"publication","summary":"The explosive growth of computational notebooks provides a unique opportunity to support computational research, but care must be taken when performing and sharing analyses in notebooks. Given these opportunities and challenges, we have compiled a set of rules, tips, tools, and example notebooks to help guide Jupyter Notebook authors. While we focus on a few core uses of Jupyter Notebooks observed in our own research, many of these rules can be applied to other computational notebooks and use cases.","tags":[],"title":"Ten simple rules for writing and sharing computational analyses in Jupyter Notebooks","type":"publication"}]