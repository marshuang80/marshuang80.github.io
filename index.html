<!doctype html>
<!-- This site was created with Wowchemy. https://www.wowchemy.com --><!-- Last Published: January 29, 2023 -->
<html lang=en-us>

<head>
  <meta charset=utf-8>
  <meta name=viewport content="width=device-width,initial-scale=1">
  <meta http-equiv=x-ua-compatible content="IE=edge">
  <meta name=generator content="Wowchemy 5.7.0 for Hugo">
  <link rel=preconnect href=https://fonts.gstatic.com crossorigin>
  <link rel=preload as=style
    href="https://fonts.googleapis.com/css2?family=B612+Mono&family=B612:wght@400;700&family=Jura:wght@400;700&display=swap">
  <link rel=stylesheet
    href="https://fonts.googleapis.com/css2?family=B612+Mono&family=B612:wght@400;700&family=Jura:wght@400;700&display=swap"
    media=print onload='this.media="all"'>
  <link rel=stylesheet href=/css/vendor-bundle.min.16f785cdb553c8c4431db6775122af35.css media=print
    onload='this.media="all"'>
  <link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.2/css/academicons.min.css
    integrity="sha512-KlJCpRsLf+KKu2VQa5vmRuClRFjxc5lXO03ixZt82HZUk41+1I0bD8KBSA0fY290ayMfWYI9udIqeOWSu1/uZg=="
    crossorigin=anonymous media=print onload='this.media="all"'>
  <link rel=stylesheet href=/css/wowchemy.af55899d8b924748b901d470aa7b0bd6.css>
  <link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'>
  <link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"'
    disabled>
  <meta name=author content="Mars (Shih-Cheng) Huang">
  <meta name=description
    content="A highly-customizable Hugo academic resume theme powered by Wowchemy website builder.">
  <link rel=alternate hreflang=en-us href=https://marshuang80.github.io />
  <link rel=canonical href=https://marshuang80.github.io />
  <link rel=manifest href=/manifest.webmanifest>
  <link rel=icon type=image/png
    href=/media/icon_hu687e722fa5af903774003502d32d2ddb_42108_32x32_fill_lanczos_center_3.png>
  <link rel=apple-touch-icon type=image/png
    href=/media/icon_hu687e722fa5af903774003502d32d2ddb_42108_180x180_fill_lanczos_center_3.png>
  <meta name=theme-color content="#1565c0">
  <meta property="twitter:card" content="summary">
  <meta property="twitter:site" content="@wowchemy">
  <meta property="twitter:creator" content="@wowchemy">
  <meta property="twitter:image"
    content="https://marshuang80.github.io/media/icon_hu687e722fa5af903774003502d32d2ddb_42108_512x512_fill_lanczos_center_3.png">
  <meta property="og:site_name" content="Mars Huang">
  <meta property="og:url" content="https://marshuang80.github.io/">
  <meta property="og:title" content="Mars Huang">
  <meta property="og:description"
    content="A highly-customizable Hugo academic resume theme powered by Wowchemy website builder.">
  <meta property="og:image"
    content="https://marshuang80.github.io/media/icon_hu687e722fa5af903774003502d32d2ddb_42108_512x512_fill_lanczos_center_3.png">
  <meta property="og:locale" content="en-us">
  <meta property="og:updated_time" content="2022-10-24T00:00:00+00:00">
  <script
    type=application/ld+json>{"@context":"https://schema.org","@type":"WebSite","potentialAction":{"@type":"SearchAction","target":"https://marshuang80.github.io?q={search_term_string}","query-input":"required name=search_term_string"},"url":"https://marshuang80.github.io"}</script>
  <script src=https://identity.netlify.com/v1/netlify-identity-widget.js></script>
  <link rel=alternate href=/index.xml type=application/rss+xml title="Mars Huang">
  <title>Mars Huang</title>
</head>

<body id=top data-spy=scroll data-offset=70 data-target=#navbar-main class=page-wrapper
  data-wc-page-id=3976528693a0108357f4928017600865>
  <script src=/js/wowchemy-init.min.ec9d49ca50e4b80bdb08f0417a28ed84.js></script>
  <aside class=search-modal id=search>
    <div class=container>
      <section class=search-header>
        <div class="row no-gutters justify-content-between mb-3">
          <div class=col-6>
            <h1>Search</h1>
          </div>
          <div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i
                class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div>
        </div>
        <div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off
            autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div>
      </section>
      <section class=section-search-results>
        <div id=search-hits></div>
      </section>
    </div>
  </aside>
  <div class="page-header header--fixed">
    <header>
      <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main>
        <div class=container-xl>
          <div class="d-none d-lg-inline-flex"><a class=navbar-brand href= />Mars Huang</a></div><button type=button
            class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content
            aria-expanded=false aria-label="Toggle navigation">
            <span><i class="fas fa-bars"></i></span></button>
          <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href= />Mars Huang</a>
          </div>
          <div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content>
            <ul class="navbar-nav d-md-inline-flex">
              <li class=nav-item><a class=nav-link href=/#about data-target=#about><span>About</span></a></li>
              <li class=nav-item><a class=nav-link href=/#featured data-target=#featured><span>Featured</span></a></li>
              <li class=nav-item><a class=nav-link href=/#publications
                  data-target=#publications><span>Publications</span></a></li>
              <li class=nav-item><a class=nav-link href=/#experiences
                  data-target=#experiences><span>Experiences</span></a></li>
              <li class=nav-item><a class=nav-link href=/#photos data-target=#photos><span>Photography</span></a></li>
            </ul>
          </div>
          <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
            <li class="nav-item d-none d-lg-inline-flex"><a class=nav-link href=https://twitter.com/MarsScHuang
                data-toggle=tooltip data-placement=bottom title="Follow me on Twitter" target=_blank rel=noopener
                aria-label="Follow me on Twitter"><i class="fab fa-twitter" aria-hidden=true></i></a></li>
            <li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search"
                  aria-hidden=true></i></a></li>
            <li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown
                aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a>
              <div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span></a>
                <a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span></a>
                <a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a>
              </div>
            </li>
          </ul>
        </div>
      </nav>
    </header>
  </div>
  <div class=page-body><span class="js-widget-page d-none"></span>
    <section id=about class="home-section wg-about-avatar">
      <div class=home-section-bg></div>
      <div class=container>
        <div id=profile>
          <div class=avatar-wrapper><img class="avatar avatar-circle"
              src=/authors/admin/avatar_hu0647cedca97c4c8f561204cc83f5d37a_415564_150x150_fill_q75_lanczos_center.jpg
              alt="Mars (Shih-Cheng) Huang" width=150 height=150>
            <span class=avatar-emoji>ðŸš€</span>
          </div>
          <div class=portrait-title>
            <h2>Mars (Shih-Cheng) Huang</h2>
            <h3>Ph.D. Candidate @</h3>
            <h3><a href=https://www.stanford.edu/ target=_blank rel=noopener><span>Stanford University</span></a></h3>
          </div>
          <ul class=network-icon aria-hidden=true>
            <li><a href=https://twitter.com/MarsScHuang target=_blank rel=noopener aria-label=twitter
                data-toggle=tooltip data-placement=top title="Follow me on Twitter"><i
                  class="fab fa-twitter big-icon"></i></a></li>
            <li><a href="https://scholar.google.com/citations?hl=en&user=RLMiaZUAAAAJ" target=_blank rel=noopener
                aria-label=graduation-cap><i class="fas fa-graduation-cap big-icon"></i></a></li>
            <li><a href=https://github.com/marshuang80 target=_blank rel=noopener aria-label=github><i
                  class="fab fa-github big-icon"></i></a></li>
            <li><a href=https://www.linkedin.com/in/mschuang/ target=_blank rel=noopener aria-label=linkedin><i
                  class="fab fa-linkedin big-icon"></i></a></li>
            <li><a href=/uploads/resume.pdf target=_blank rel=noopener aria-label=cv><i
                  class="ai ai-cv big-icon"></i></a></li>
          </ul>
          <div class="article-style pt-2 d-flex justify-content-center">
            <div class=bio-text>
              <p>Hi there - I am a PhD candidate in Biomedical Informatics at Stanford University, studying artificial
                intelligence and clinical informatics. I am currently advised by <a
                  href=https://ai.stanford.edu/~syyeung/ target=_blank rel=noopener>Serena Yeung</a>, <a
                  href=https://profiles.stanford.edu/curtis-langlotz target=_blank rel=noopener>Curtis Langlotz</a>, <a
                  href=https://profiles.stanford.edu/nigam-shah target=_blank rel=noopener>Nigam Shah</a> and previously
                by <a href="https://scholar.google.com/citations?user=z1UtMSYAAAAJ&hl=en" target=_blank
                  rel=noopener>Matthew P. Lungren</a>. I am affiliated with Stanford&rsquo;s <a
                  href=https://marvl.stanford.edu/index.html target=_blank rel=noopener>MARVL</a> lab and 
                  <a href=https://aimi.stanford.edu/ target=_blank rel=noopener>AIMI</a> Center, and have experience 
                  working at 
                  <a href=https://research.google/teams/perception/ target=_blank rel=noopener>Google Research </a>,
                  <a href=https://www.microsoft.com/en-us/research/lab/microsoft-health-futures/ target=_blank rel=noopener>Microsoft Research </a>,
                  <a href=https://www.salesforceairesearch.com/ target=_blank rel=noopener>Salesforce AI research</a> and 
                  <a href=https://chanzuckerberg.com/science/institutes/ target=_blank rel=noopener>The ChanZuckerberg Initiative.</a></p>

              <p>My research focuses on the intersection of multimodal and self-supervised
                learning, and the application of these methods to improve
                healthcare.</p>
            </div>
          </div>
        </div>
      </div>
    </section>
    <section id=featured class="home-section wg-collection">
      <div class=home-section-bg></div>
      <div class=container>
        <div class=row>
          <div
            class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start">
            <h1 class=mb-0>Featured Publications</h1>
          </div>
          <div class="col-12 col-lg-8">

            <div class="card-simple view-card">
              <div class=article-metadata>
                <div><span>Yuhui Zhang</span>, <span>Jeff Z HaoChen</span>, <span class=author-highlighted>Mars
                    (Shih-Cheng) Huang</span>, <span>Kuan-Chieh Wang</span>, <span>James Zou</span>, <span>Serena
                    Yeung</span></div><span class=article-date>January, 2023</span>
                <span class=middot-divider></span>
                <span class=pub-publication>ICLR</span>
              </div><a href=/publication/dr-ml />
              <div class=img-hover-zoom><img
                  src=/publication/dr-ml/featured_hub8739e2f7e68d2897bf9a51248f5d175_382214_808x455_fill_q75_h2_lanczos_smart1_3.webp
                  height=455 width=808 class=article-banner
                  alt="DrML: Diagnosing and Rectifying Vision Models using Language" loading=lazy></div></a>
              <div class="section-subheading article-title mb-1 mt-3"><a href=/publication/dr-ml />DrML: Diagnosing and
                Rectifying Vision Models using Language</a></div><a href=/publication/dr-ml/ class=summary-link>
                <div class=article-style>
                  <p>The traditional process of diagnosing model behaviors in deployment settings involves
                    labor-intensive data acquisition and annotation. Our proposed method, DrML, can discover high-error
                    data slices, identify influential attributes and further rectify undesirable model behaviors,
                    without requiring any visual data. Through a combination of theoretical explanation and empirical
                    verification, we present conditions under which classifiers trained on embeddings from one modality
                    can be equivalently applied to embeddings from another modality.</p>
                </div>
              </a>
              <div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm"
                  href="https://openreview.net/forum?id=losu6IAaPeB" target=_blank rel=noopener>PDF</a>
                <a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
                  data-filename=/publication/dr-ml/cite.bib>Cite</a>
                <a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/yuhui-zh15/model_audit
                  target=_blank rel=noopener>Code</a>
              </div>
            </div>


            <div class="card-simple view-card">
              <div class=article-metadata>
                <div><span class=author-highlighted>Mars (Shih-Cheng) Huang</span><i
                    class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>,
                  <span>Anuj Pareek</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip
                    title="Equal contribution"></i>, <span>Malte Jensen</span>, <span>Matthew P. Lungren</span>,
                  <span>Serena Yeung</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip
                    title="Equal contribution"></i>, <span>Akshay S. Chaudhari</span><i
                    class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i></div>
                <span class=article-date>January, 2023</span>
                <span class=middot-divider></span>
                <span class=pub-publication>Nature Digital Medicine</span>
              </div><a href=/publication/ssl />
              <div class=img-hover-zoom><img
                  src=/publication/ssl/featured_hu7c5ff2c1e9ad51f00bd6875a80ad2826_468879_808x455_fill_q75_h2_lanczos_smart1_3.webp
                  height=455 width=808 class=article-banner
                  alt="Self-supervised learning for medical image classification: a systematic review and implementation guidelines"
                  loading=lazy></div></a>
              <div class="section-subheading article-title mb-1 mt-3"><a href=/publication/ssl />Self-supervised
                learning for medical image classification: a systematic review and implementation guidelines</a></div><a
                href=/publication/ssl/ class=summary-link>
                <div class=article-style>
                  <p>In this review, we provide consistent descriptions of different self-supervised learning strategies
                    and compose a systematic review of papers published between 2012 and 2022 on PubMed, Scopus, and
                    ArXiv that applied self-supervised learning to medical imaging classification. With this
                    comprehensive effort, we synthesize the collective knowledge of prior work and provide
                    implementation guidelines for future researchers interested in applying self-supervised learning to
                    their development of medical imaging classification models.</p>
                </div>
              </a>
              <div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm"
                  href=/publication/ssl/conference-paper.pdf target=_blank rel=noopener>PDF</a>
                <a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
                  data-filename=/publication/ssl/cite.bib>Cite</a>
              </div>
            </div>
            <div class="card-simple view-card">
              <div class=article-metadata>
                <div><span class=author-highlighted>Mars (Shih-Cheng) Huang</span>, <span>Akshay S. Chaudhari</span>,
                  <span>Curtis P. Langlotz</span>, <span>Nigam Shah</span>, <span>Serena Yeung</span><i
                    class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>,
                  <span>Matthew P. Lungren</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip
                    title="Equal contribution"></i></div><span class=article-date>November, 2022</span>
                <span class=middot-divider></span>
                <span class=pub-publication>Nature Communications</span>
              </div><a href=/publication/infectious />
              <div class=img-hover-zoom><img
                  src=/publication/infectious/featured_hu7e55216efe0083e82003e78abbe6d877_128440_808x455_fill_q75_h2_lanczos_smart1.webp
                  height=455 width=808 class=article-banner
                  alt="Developing medical imaging AI for emerging infectious diseases" loading=lazy></div></a>
              <div class="section-subheading article-title mb-1 mt-3"><a href=/publication/infectious />Developing
                medical imaging AI for emerging infectious diseases</a></div><a href=/publication/infectious/
                class=summary-link>
                <div class=article-style>
                  <p>In this review, we provide an evidence-based roadmap for how machine learning technologies in
                    medical imaging can be used to battle ongoing and future pandemics. Specifically, we focus in each
                    section on the four most pressing issues, namely - needfinding, dataset curation, model development
                    and subsequent evaluation, and post-deployment considerations.</p>
                </div>
              </a>
              <div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm"
                  href=https://www.nature.com/articles/s41467-022-34234-4 target=_blank rel=noopener>PDF</a>
                <a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
                  data-filename=/publication/infectious/cite.bib>Cite</a>
                <a class="btn btn-outline-primary btn-page-header btn-sm"
                  href=https://doi.org/https://doi.org/10.48550/arXiv.2111.11665 target=_blank rel=noopener>DOI</a>
              </div>
            </div>
            <div class="card-simple view-card">
              <div class=article-metadata>
                <div><span class=author-highlighted>Mars (Shih-Cheng) Huang</span>, <span>Liyue Shen</span>,
                  <span>Matthew P Lungren</span>, <span>Serena Yeung</span></div><span class=article-date>October,
                  2021</span>
                <span class=middot-divider></span>
                <span class=pub-publication>ICCV</span>
              </div><a href=/publication/gloria />
              <div class=img-hover-zoom><img src=/publication/gloria/featured.png height=455 width=808
                  class=article-banner
                  alt="GLoRIA: A Multimodal Global-Local Representation Learning Framework for Label-Efficient Medical Image Recognition"
                  loading=lazy></div></a>
              <div class="section-subheading article-title mb-1 mt-3"><a href=/publication/gloria />GLoRIA: A Multimodal
                Global-Local Representation Learning Framework for Label-Efficient Medical Image Recognition</a></div><a
                href=/publication/gloria/ class=summary-link>
                <div class=article-style>
                  <p>The purpose of this work is to develop label-efficient multimodal medical imaging representations
                    by leveraging radiology reports. Specifically, we propose an attention-based framework (GLoRIA) for
                    learning global and local representations by contrasting image sub-regions and words in the paired
                    report. In addition, we propose methods to leverage the learned representations for various
                    downstream medical image recognition tasks with limited labels.</p>
                </div>
              </a>
              <div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm"
                  href=https://openaccess.thecvf.com/content/ICCV2021/html/Huang_GLoRIA_A_Multimodal_Global-Local_Representation_Learning_Framework_for_Label-Efficient_Medical_ICCV_2021_paper.html
                  target=_blank rel=noopener>PDF</a>
                <a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
                  data-filename=/publication/gloria/cite.bib>Cite</a>
                <a class="btn btn-outline-primary btn-page-header btn-sm"
                  href=https://doi.org/https://doi.org/10.1101/2020.11.27.368811 target=_blank rel=noopener>DOI</a>
              </div>
            </div>
            <div class="card-simple view-card">
              <div class=article-metadata>
                <div><span class=author-highlighted>Mars (Shih-Cheng) Huang</span><i
                    class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>,
                  <span>Anuj Pareek</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip
                    title="Equal contribution"></i>, <span>Saeed Seyyedi</span>, <span>Imon Banerjee</span>,
                  <span>Matthew P. Lungren</span></div><span class=article-date>October, 2020</span>
                <span class=middot-divider></span>
                <span class=pub-publication>Nature Digital Medicine</span>
              </div><a href=/publication/multimodal />
              <div class=img-hover-zoom><img
                  src=/publication/multimodal/featured_hudd148ad42da73487dd1d542f2b5fc2cf_38324_808x455_fill_q75_h2_lanczos_smart1.webp
                  height=455 width=808 class=article-banner
                  alt="Fusion of medical imaging and electronic health records using deep learning: a systematic review and implementation guidelines"
                  loading=lazy></div></a>
              <div class="section-subheading article-title mb-1 mt-3"><a href=/publication/multimodal />Fusion of
                medical imaging and electronic health records using deep learning: a systematic review and
                implementation guidelines</a></div><a href=/publication/multimodal/ class=summary-link>
                <div class=article-style>
                  <p>In this reivew, we describe different data fusion techniques that can be applied to combine medical
                    imaging with EHR, and systematically review medical data fusion literature published between 2012
                    and 2020. By means of this systematic review, we present current knowledge, summarize important
                    results and provide implementation guidelines to serve as a reference for researchers interested in
                    the application of multimodal fusion in medical imaging.</p>
                </div>
              </a>
              <div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm"
                  href=https://www.nature.com/articles/s41746-020-00341-z target=_blank rel=noopener>PDF</a>
                <a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
                  data-filename=/publication/multimodal/cite.bib>Cite</a>
                <a class="btn btn-outline-primary btn-page-header btn-sm"
                  href=https://doi.org/https://doi.org/10.1038/s41746-020-00341-z target=_blank rel=noopener>DOI</a>
              </div>
            </div>
            <div class=see-all><a href=/publication />See all publications
              <i class="fas fa-angle-right"></i></a>
            </div>
          </div>
        </div>
      </div>
    </section>
    <section id=publications class="home-section wg-collection">
      <div class=home-section-bg></div>
      <div class=container>
        <div class=row>
          <div
            class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start">
            <h1 class=mb-0>All Publications</h1>
          </div>
          <div class="col-12 col-lg-8">
            <div class="alert alert-note">
              <div>Quickly discover relevant content by <a href=./publication />filtering publications</a>.</div>
            </div>
            <div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon"
                aria-hidden=true></i>
              <span class="article-metadata li-cite-author"><span>Yuhui Zhang</span>, <span>Jeff Z HaoChen</span>, <span
                  class=author-highlighted>Mars (Shih-Cheng) Huang</span>, <span>Kuan-Chieh Wang</span>, <span>James
                  Zou</span>, <span>Serena Yeung</span></span>
              (2023).
              <a href=/publication/dr-ml />DrML: Diagnosing and Rectifying Vision Models using Language</a>.
              ICLR.<p><a class="btn btn-outline-primary btn-page-header btn-sm"
                  href="https://openreview.net/forum?id=losu6IAaPeB" target=_blank rel=noopener>PDF</a>
                <a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
                  data-filename=/publication/dr-ml/cite.bib>Cite</a>
                <a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/yuhui-zh15/model_audit
                  target=_blank rel=noopener>Code</a>
              </p>
            </div>
            <div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon"
                aria-hidden=true></i>
              <span class="article-metadata li-cite-author"><span>Rui Yan</span>, <span>Liangqiong Qu</span>,
                <span>Qingyue Wei</span>, <span class=author-highlighted>Mars (Shih-Cheng) Huang</span>, <span>Liyue
                  Shen</span>, <span>Daniel Rubin</span>, <span>Lei Xing</span>, <span>Yuyin Zhou</span></span>
              (2023).
              <a href=/publication/ssl-federated />Label-efficient self-supervised federated learning for tackling data
              heterogeneity in medical imaging</a>.
              IEEE Transactions on Medical Imaging.<p><a class="btn btn-outline-primary btn-page-header btn-sm"
                  href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10004993" target=_blank
                  rel=noopener>PDF</a>
                <a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
                  data-filename=/publication/ssl-federated/cite.bib>Cite</a>
                <a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/rui-yan/SSL-FL
                  target=_blank rel=noopener>Code</a>
                <a class="btn btn-outline-primary btn-page-header btn-sm"
                  href=https://doi.org/https://doi.org/10.1109/TMI.2022.3233574 target=_blank rel=noopener>DOI</a>
              </p>
            </div>
            <div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon"
                aria-hidden=true></i>
              <span class="article-metadata li-cite-author"><span class=author-highlighted>Mars (Shih-Cheng)
                  Huang</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip
                  title="Equal contribution"></i>, <span>Anuj Pareek</span><i class="author-notes fas fa-info-circle"
                  data-toggle=tooltip title="Equal contribution"></i>, <span>Malte Jensen</span>, <span>Matthew P.
                  Lungren</span>, <span>Serena Yeung</span><i class="author-notes fas fa-info-circle"
                  data-toggle=tooltip title="Equal contribution"></i>, <span>Akshay S. Chaudhari</span><i
                  class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i></span>
              (2023).
              <a href=/publication/ssl />Self-supervised learning for medical image classification: a systematic review
              and implementation guidelines</a>.
              Nature Digital Medicine (Under Review).<p><a class="btn btn-outline-primary btn-page-header btn-sm"
                  href=/publication/ssl/conference-paper.pdf target=_blank rel=noopener>PDF</a>
                <a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
                  data-filename=/publication/ssl/cite.bib>Cite</a>
              </p>
            </div>
            <div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon"
                aria-hidden=true></i>
              <span class="article-metadata li-cite-author"><span>Yuhui Zhang</span>, <span
                  class=author-highlighted>Mars (Shih-Cheng) Huang</span>, <span>Zhengping Zhou,</span>, <span>Matthew
                  P. Lungren</span>, <span>Serena Yeung</span></span>
              (2022).
              <a href=/publication/transformers-segmentation />Adapting pre-trained vision transformers from 2D to 3D
              through weight inflation improves medical image segmentation</a>.
              ML4H.<p><a class="btn btn-outline-primary btn-page-header btn-sm"
                  href=https://proceedings.mlr.press/v193/zhang22a.html target=_blank rel=noopener>PDF</a>
                <a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
                  data-filename=/publication/transformers-segmentation/cite.bib>Cite</a>
                <a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/yuhui-zh15/TransSeg
                  target=_blank rel=noopener>Code</a>
              </p>
            </div>
            <div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon"
                aria-hidden=true></i>
              <span class="article-metadata li-cite-author"><span class=author-highlighted>Mars (Shih-Cheng)
                  Huang</span>, <span>Akshay S. Chaudhari</span>, <span>Curtis P. Langlotz</span>, <span>Nigam
                  Shah</span>, <span>Serena Yeung</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip
                  title="Equal contribution"></i>, <span>Matthew P. Lungren</span><i
                  class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i></span>
              (2022).
              <a href=/publication/infectious />Developing medical imaging AI for emerging infectious diseases</a>.
              Nature Communications.<p><a class="btn btn-outline-primary btn-page-header btn-sm"
                  href=https://www.nature.com/articles/s41467-022-34234-4 target=_blank rel=noopener>PDF</a>
                <a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
                  data-filename=/publication/infectious/cite.bib>Cite</a>
                <a class="btn btn-outline-primary btn-page-header btn-sm"
                  href=https://doi.org/https://doi.org/10.1038/s41467-022-34234-4 target=_blank rel=noopener>DOI</a>
              </p>
            </div>
            <div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon"
                aria-hidden=true></i>
              <span class="article-metadata li-cite-author"><span>Judy Wawira Gichoya</span>, <span>Imon
                  Banerjee</span>, <span>Ananth Reddy Bhimireddy</span>, <span>John L Burns</span>, <span>Leo Anthony
                  Celi</span>, <span>Li-Ching Chen</span>, <span>Ramon Correa</span>, <span>Natalie Dullerud</span>,
                <span>Marzyeh Ghassemi</span>, <span class=author-highlighted>Mars (Shih-Cheng) Huang</span>,
                <span>Po-Chih Kuo</span>, <span>Matthew P Lungren</span>, <span>Lyle J Palmer</span>, <span>Brandon J
                  Price</span>, <span>Saptarshi Purkayastha</span>, <span>Ayis T Pyrros</span>, <span>Lauren
                  Oakden-Rayner</span>, <span>Chima Okechukwu</span>, <span>Laleh Seyyed-Kalantari</span>, <span>Hari
                  Trivedi</span>, <span>Ryan Wang</span>, <span>Zachary Zaiman</span>, <span>Haoran Zhang</span></span>
              (2022).
              <a href=/publication/ai_race />AI recognition of patient race in medical imaging: a modelling study</a>.
              The Lancet Digital Health.<p><a class="btn btn-outline-primary btn-page-header btn-sm"
                  href=https://www.sciencedirect.com/science/article/pii/S2589750022000632 target=_blank
                  rel=noopener>PDF</a>
                <a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
                  data-filename=/publication/ai_race/cite.bib>Cite</a>
                <a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/Emory-HITI/AI-Vengers
                  target=_blank rel=noopener>Code</a>
                <a class="btn btn-outline-primary btn-page-header btn-sm"
                  href=https://doi.org/https://doi.org/10.1016/S2589-7500%2822%2900063-2 target=_blank
                  rel=noopener>DOI</a>
              </p>
            </div>
            <div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon"
                aria-hidden=true></i>
              <span class="article-metadata li-cite-author"><span>Andre Esteva</span>, <span>Jean Feng</span>,
                <span>Douwe van der Wal</span>, <span class=author-highlighted>Mars (Shih-Cheng) Huang</span>,
                <span>Jeffry P Simko</span>, <span>Sandy DeVries</span>, <span>Emmalyn Chen</span>, <span>Edward M
                  Schaeffer</span>, <span>Todd M Morgan</span>, <span>Yilun Sun</span>, <span>Amirata Ghorbani</span>,
                <span>Nikhil Naik</span>, <span>Dhruv Nathawani</span>, <span>Richard Socher</span>, <span>Jeff M
                  Michalski</span>, <span>Mack Roach III</span>, <span>Thomas M Pisansky</span>, <span>Jedidiah M
                  Monson</span>, <span>Farah Naz</span>, <span>James Wallace</span>, <span>Michelle J Ferguson</span>,
                <span>Jean-Paul Bahary</span>, <span>James Zou</span>, <span>Matthew Lungren</span>, <span>Serena
                  Yeung</span>, <span>Ashley E Ross</span>, <span>Howard M Sandler</span>, <span>Phuoc T Tran</span>,
                <span>Daniel E Spratt</span>, <span>Stephanie Pugh</span>, <span>Felix Y Feng</span>, <span>Osama
                  Mohamad</span>, <span>NRG Prostate Cancer AI Consortium</span></span>
              (2022).
              <a href=/publication/prostate_multimodal />Prostate cancer therapy personalization via multi-modal deep
              learning on randomized phase III clinical trials</a>.
              Nature Digital Medicine.<p><a class="btn btn-outline-primary btn-page-header btn-sm"
                  href=https://www.nature.com/articles/s41746-022-00613-w target=_blank rel=noopener>PDF</a>
                <a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
                  data-filename=/publication/prostate_multimodal/cite.bib>Cite</a>
                <a class="btn btn-outline-primary btn-page-header btn-sm"
                  href=https://doi.org/https://doi.org/10.1038/s41746-022-00613-w target=_blank rel=noopener>DOI</a>
              </p>
            </div>
            <div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon"
                aria-hidden=true></i>
              <span class="article-metadata li-cite-author"><span>Andre Esteva</span>, <span>Jean Feng</span>, <span
                  class=author-highlighted>Mars (Shih-Cheng) Huang</span>, <span>Douwe van der Wal</span>, <span>Jeffry
                  Simko</span>, <span>Sandy DeVries</span>, <span>Emmalyn Chen</span>, <span>Edward M Schaeffer</span>,
                <span>Todd Matthew Morgan</span>, <span>Jedidiah Mercer Monson</span>, <span>Farah Naz</span>,
                <span>James Wallace</span>, <span>Michelle J Ferguson</span>, <span>Jean-Paul Bahary</span>,
                <span>Howard M Sandler</span>, <span>Phuoc T Tran</span>, <span>Daniel Eidelberg Spratt</span>,
                <span>Stephanie L Pugh</span>, <span>Felix Y Feng</span>, <span>Osama Mohamad</span></span>
              (2022).
              <a href=/publication/prostate_multimodal_oncology />Development and validation of a prognostic AI
              biomarker using multi-modal deep learning with digital histopathology in localized prostate cancer on NRG
              Oncology phase III clinical trials.</a>.
              Journal of Clinical Oncology.<p><a class="btn btn-outline-primary btn-page-header btn-sm"
                  href=https://ascopubs.org/doi/abs/10.1200/JCO.2022.40.6_suppl.222 target=_blank rel=noopener>PDF</a>
                <a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
                  data-filename=/publication/prostate_multimodal_oncology/cite.bib>Cite</a>
                <a class="btn btn-outline-primary btn-page-header btn-sm"
                  href=https://doi.org/https://doi.org/10.1200/JCO.2022.40.6_suppl.222 target=_blank
                  rel=noopener>DOI</a>
              </p>
            </div>
            <div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon"
                aria-hidden=true></i>
              <span class="article-metadata li-cite-author"><span>Jiangdian Song</span>, <span
                  class=author-highlighted>Mars (Shih-Cheng) Huang</span>, <span>Brendan Kelly</span>, <span>Guanqun
                  Liao</span>, <span>Jing-yun Shi</span>, <span>Ning Wu</span>, <span>Weimin Li</span>, <span>Zaiyi
                  Liu</span>, <span>Lei Cui</span>, <span>Matthew P Lungren</span>, <span>Michael Moseley</span>,
                <span>Peng Gao</span>, <span>Jie Tian</span>, <span>Kristen Yeom</span></span>
              (2021).
              <a href=/publication/lung_segmentation />Automatic lung nodule segmentation and intra-nodular
              heterogeneity image generation</a>.
              IEEE Journal of Biomedical and Health Informatics.<p><a
                  class="btn btn-outline-primary btn-page-header btn-sm"
                  href=https://ieeexplore.ieee.org/abstract/document/9652062 target=_blank rel=noopener>PDF</a>
                <a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
                  data-filename=/publication/lung_segmentation/cite.bib>Cite</a>
                <a class="btn btn-outline-primary btn-page-header btn-sm"
                  href=https://doi.org/https://doi.org/10.1109/JBHI.2021.3135647 target=_blank rel=noopener>DOI</a>
              </p>
            </div>
            <div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon"
                aria-hidden=true></i>
              <span class="article-metadata li-cite-author"><span>Yuyin Zhou</span><i
                  class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>, <span
                  class=author-highlighted>Mars (Shih-Cheng) Huang</span><i class="author-notes fas fa-info-circle"
                  data-toggle=tooltip title="Equal contribution"></i>, <span>Jason Alan Fries</span>, <span>Alaa
                  Youssef</span>, <span>Timothy J. Amrhein</span>, <span>Marcello Chang</span>, <span>Imon
                  Banerjee</span>, <span>Daniel Rubin</span>, <span>Lei Xing</span>, <span>Nigam Shah</span>,
                <span>Matthew P. Lungren</span></span>
              (2021).
              <a href=/publication/radfusion />RadFusion: Benchmarking Performance and Fairness for Multimodal Pulmonary
              Embolism Detection from CT and EHR</a>.
              arXiv.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2111.11665
                  target=_blank rel=noopener>PDF</a>
                <a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
                  data-filename=/publication/radfusion/cite.bib>Cite</a>
                <a class="btn btn-outline-primary btn-page-header btn-sm"
                  href=https://doi.org/https://doi.org/10.48550/arXiv.2111.11665 target=_blank rel=noopener>DOI</a>
              </p>
            </div>
            <div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon"
                aria-hidden=true></i>
              <span class="article-metadata li-cite-author"><span class=author-highlighted>Mars (Shih-Cheng)
                  Huang</span>, <span>Liyue Shen</span>, <span>Matthew P Lungren</span>, <span>Serena
                  Yeung</span></span>
              (2021).
              <a href=/publication/gloria />GLoRIA: A Multimodal Global-Local Representation Learning Framework for
              Label-Efficient Medical Image Recognition</a>.
              ICCV.<p><a class="btn btn-outline-primary btn-page-header btn-sm"
                  href=https://openaccess.thecvf.com/content/ICCV2021/html/Huang_GLoRIA_A_Multimodal_Global-Local_Representation_Learning_Framework_for_Label-Efficient_Medical_ICCV_2021_paper.html
                  target=_blank rel=noopener>PDF</a>
                <a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
                  data-filename=/publication/gloria/cite.bib>Cite</a>
                <a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/marshuang80/gloria
                  target=_blank rel=noopener>Code</a>
              </p>
            </div>
            <div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon"
                aria-hidden=true></i>
              <span class="article-metadata li-cite-author"><span class=author-highlighted>Mars (Shih-Cheng)
                  Huang</span>, <span>Anuj Pareek</span>, <span>Roham Zamanian</span>, <span>Imon Banerjee</span>,
                <span>Matthew P. Lungren</span></span>
              (2020).
              <a href=/publication/pe_multimodal />Multimodal fusion with deep neural networks for leveraging CT imaging
              and electronic health record: a case-study in pulmonary embolism detection</a>.
              Nature Scientific Reports.<p><a class="btn btn-outline-primary btn-page-header btn-sm"
                  href=https://www.nature.com/articles/s41598-020-78888-w target=_blank rel=noopener>PDF</a>
                <a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
                  data-filename=/publication/pe_multimodal/cite.bib>Cite</a>
                <a class="btn btn-outline-primary btn-page-header btn-sm"
                  href=https://doi.org/https://doi.org/10.1038/s41598-020-78888-w target=_blank rel=noopener>DOI</a>
              </p>
            </div>
            <div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon"
                aria-hidden=true></i>
              <span class="article-metadata li-cite-author"><span>Ashton Teng</span><i
                  class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>,
                <span>Blanca Villanueva</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip
                  title="Equal contribution"></i>, <span>Derek Jow</span>, <span class=author-highlighted>Mars
                  (Shih-Cheng) Huang</span>, <span>Samantha N Piekos</span>, <span>Russ B Altman</span></span>
              (2020).
              <a href=/publication/bgv />Biomedical Graph Visualizer for Identifying Drug Candidates</a>.
              biorXiv.<p><a class="btn btn-outline-primary btn-page-header btn-sm"
                  href=https://www.biorxiv.org/content/10.1101/2020.11.27.368811v1.abstract target=_blank
                  rel=noopener>PDF</a>
                <a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
                  data-filename=/publication/bgv/cite.bib>Cite</a>
                <a class="btn btn-outline-primary btn-page-header btn-sm"
                  href=https://doi.org/https://doi.org/10.1101/2020.11.27.368811 target=_blank rel=noopener>DOI</a>
              </p>
            </div>
            <div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon"
                aria-hidden=true></i>
              <span class="article-metadata li-cite-author"><span class=author-highlighted>Mars (Shih-Cheng)
                  Huang</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip
                  title="Equal contribution"></i>, <span>Anuj Pareek</span><i class="author-notes fas fa-info-circle"
                  data-toggle=tooltip title="Equal contribution"></i>, <span>Saeed Seyyedi</span>, <span>Imon
                  Banerjee</span>, <span>Matthew P. Lungren</span></span>
              (2020).
              <a href=/publication/multimodal />Fusion of medical imaging and electronic health records using deep
              learning: a systematic review and implementation guidelines</a>.
              Nature Digital Medicine.<p><a class="btn btn-outline-primary btn-page-header btn-sm"
                  href=https://www.nature.com/articles/s41746-020-00341-z target=_blank rel=noopener>PDF</a>
                <a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
                  data-filename=/publication/multimodal/cite.bib>Cite</a>
                <a class="btn btn-outline-primary btn-page-header btn-sm"
                  href=https://doi.org/https://doi.org/10.1038/s41746-020-00341-z target=_blank rel=noopener>DOI</a>
              </p>
            </div>
            <div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon"
                aria-hidden=true></i>
              <span class="article-metadata li-cite-author"><span>Anirudh Joshi</span><i
                  class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>,
                <span>Sabri Eyuboglu</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip
                  title="Equal contribution"></i>, <span class=author-highlighted>Mars (Shih-Cheng) Huang</span><i
                  class="author-notes fas fa-info-circle" data-toggle=tooltip title="Equal contribution"></i>,
                <span>Jared Dunnmon</span>, <span>Arjun Soin</span>, <span>Guido Davidzon</span>, <span>Akshay
                  Chaudhari</span>, <span>Matthew P Lungren</span></span>
              (2020).
              <a href=/publication/onconet />OncoNet: Weakly Supervised Siamese Network to automate cancer treatment
              response assessment between longitudinal FDG PET/CT examinations</a>.
              arXiv.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2108.02016
                  target=_blank rel=noopener>PDF</a>
                <a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
                  data-filename=/publication/onconet/cite.bib>Cite</a>
                <a class="btn btn-outline-primary btn-page-header btn-sm"
                  href=https://doi.org/https://doi.org/10.48550/arXiv.2108.02016 target=_blank rel=noopener>DOI</a>
              </p>
            </div>
            <div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon"
                aria-hidden=true></i>
              <span class="article-metadata li-cite-author"><span class=author-highlighted>Mars (Shih-Cheng)
                  Huang</span><i class="author-notes fas fa-info-circle" data-toggle=tooltip
                  title="Equal contribution"></i>, <span>Tanay Kothari</span><i class="author-notes fas fa-info-circle"
                  data-toggle=tooltip title="Equal contribution"></i>, <span>Imon Banerjee</span>, <span>Chris
                  Chute</span>, <span>Robyn L Ball</span>, <span>Norah Borus</span>, <span>Andrew Huang</span>,
                <span>Bhavik N Patel</span>, <span>Pranav Rajpurkar</span>, <span>Jeremy Irvin</span>, <span>Jared
                  Dunnmon</span>, <span>Joseph Bledsoe</span>, <span>Katie Shpanskaya</span>, <span>Abhay
                  Dhaliwal</span>, <span>Roham Zamanian</span>, <span>Andrew Y Ng</span>, <span>Matthew P
                  Lungren</span></span>
              (2020).
              <a href=/publication/penet />PENetâ€”a scalable deep-learning model for automated diagnosis of pulmonary
              embolism using volumetric CT imaging</a>.
              Nature Digital Medicine.<p><a class="btn btn-outline-primary btn-page-header btn-sm"
                  href=https://www.nature.com/articles/s41746-020-0266-y target=_blank rel=noopener>PDF</a>
                <a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
                  data-filename=/publication/penet/cite.bib>Cite</a>
                <a class="btn btn-outline-primary btn-page-header btn-sm"
                  href=https://doi.org/https://doi.org/10.1038/s41746-020-00310-6 target=_blank rel=noopener>DOI</a>
              </p>
            </div>
            <div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon"
                aria-hidden=true></i>
              <span class="article-metadata li-cite-author"><span>Adam Rule</span>, <span>Amanda Birmingham</span>,
                <span>Cristal Zuniga</span>, <span>Ilkay Altintas</span>, <span class=author-highlighted>Mars
                  (Shih-Cheng) Huang</span>, <span>Rob Knight</span>, <span>Niema Moshiri</span>, <span>Mai H.
                  Nguyen</span>, <span>Sara Brin Rosenthal</span>, <span>Fernando PÃ©rez</span>, <span>Peter W.
                  Rose</span></span>
              (2019).
              <a href=/publication/ten_rules />Ten simple rules for writing and sharing computational analyses in
              Jupyter Notebooks</a>.
              PLOS Computational Biology.<p><a class="btn btn-outline-primary btn-page-header btn-sm"
                  href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007007&ref=https://githubhelp.com"
                  target=_blank rel=noopener>PDF</a>
                <a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
                  data-filename=/publication/ten_rules/cite.bib>Cite</a>
                <a class="btn btn-outline-primary btn-page-header btn-sm"
                  href=https://doi.org/https://doi.org/10.1371/journal.pcbi.1007007 target=_blank rel=noopener>DOI</a>
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>


    <section id=experiences class="home-section wg-experience">
      <div class=home-section-bg></div>
      <div class=container>
        <div class=row>
          <div
            class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start">
            <h1 class=mb-0>Experience</h1>
          </div>
          <div class="col-12 col-lg-8">

            <div class="row experience">
              <div class="col-auto text-center flex-column d-none d-sm-flex">
                <div class="row h-50">
                  <div class="col border-right">&nbsp;</div>
                  <div class=col>&nbsp;</div>
                </div>
                <div class=m-2><span class="badge badge-pill border">&nbsp;</span></div>
                <div class="row h-50">
                  <div class="col border-right">&nbsp;</div>
                  <div class=col>&nbsp;</div>
                </div>
              </div>
              <div class="col py-2">
                <div class=card>
                  <div class=card-body>
                    <div class="d-flex align-content-start">
                      <div class="mr-2 mb-2"><a href=https://research.google/ target=_blank rel=noopener><img
                            src=/media/icons/brands/google.svg width=56px height=56px
                            alt="Google Research" loading=lazy></a></div>
                      <div>
                        <div class="section-subheading card-title exp-title text-muted my-0">Research Scientist Intern</div>
                        <div class="section-subheading card-title exp-company text-muted my-0"><a
                            href=https://research.google/ target=_blank rel=noopener> Google Research</a></div>
                        <div class="text-muted exp-meta">September 2023 â€“ Present
                          <span class=middot-divider></span>
                          <span>Mountain View</span>
                        </div>
                      </div>
                    </div>
                    <div class=card-text>
                      <p> Designed object embeddings to improve dense semantic understanding in Vision Language Models (VLMs) and curated a multi-image Visual Question Answering dataset to benchmark VLMâ€™s dense semantic understanding
                      </p>
                      <p>
                      </p>
                    </div>
                  </div>
                </div>
              </div>
            </div>

            <div class="row experience">
              <div class="col-auto text-center flex-column d-none d-sm-flex">
                <div class="row h-50">
                  <div class="col border-right">&nbsp;</div>
                  <div class=col>&nbsp;</div>
                </div>
                <div class=m-2><span class="badge badge-pill border">&nbsp;</span></div>
                <div class="row h-50">
                  <div class="col border-right">&nbsp;</div>
                  <div class=col>&nbsp;</div>
                </div>
              </div>
              <div class="col py-2">
                <div class=card>
                  <div class=card-body>
                    <div class="d-flex align-content-start">
                      <div class="mr-2 mb-2"><a href=https://www.microsoft.com/en-us/research/lab/microsoft-health-futures/ target=_blank rel=noopener><img
                            src=/media/icons/brands/microsoft.svg width=56px height=56px
                            alt="Microsoft Research" loading=lazy></a></div>
                      <div>
                        <div class="section-subheading card-title exp-title text-muted my-0">Research Scientist Intern</div>
                        <div class="section-subheading card-title exp-company text-muted my-0"><a
                            href=https://www.microsoft.com/en-us/research/lab/microsoft-health-futures/ target=_blank rel=noopener> Microsoft Research</a></div>
                        <div class="text-muted exp-meta">June 2023 â€“ September 2023
                          <span class=middot-divider></span>
                          <span>Seattle</span>
                        </div>
                      </div>
                    </div>
                    <div class=card-text>
                      <p> Developed a VLM for generating radiology reports from Chest X-rays that achieves state-of-the-art performance 
                      </p>
                      <p>
                      </p>
                    </div>
                  </div>
                </div>
              </div>
            </div>



            <div class="row experience">
              <div class="col-auto text-center flex-column d-none d-sm-flex">
                <div class="row h-50">
                  <div class=col>&nbsp;</div>
                  <div class=col>&nbsp;</div>
                </div>
                <div class=m-2><span class="badge badge-pill border">&nbsp;</span></div>
                <div class="row h-50">
                  <div class="col border-right">&nbsp;</div>
                  <div class=col>&nbsp;</div>
                </div>
              </div>
              <div class="col py-2">
                <div class=card>
                  <div class=card-body>
                    <div class="d-flex align-content-start">
                      <div class="mr-2 mb-2"><a href=https://www.salesforceairesearch.com/ target=_blank
                          rel=noopener><img src=/media/icons/brands/org-s.svg width=56px height=56px alt=Salesforce
                            loading=lazy></a></div>
                      <div>
                        <div class="section-subheading card-title exp-title text-muted my-0">AI Research Summer Intern
                        </div>
                        <div class="section-subheading card-title exp-company text-muted my-0"><a
                            href=https://www.salesforceairesearch.com/ target=_blank rel=noopener>Salesforce</a></div>
                        <div class="text-muted exp-meta">June 2021 â€“
                          September 2021
                          <span class=middot-divider></span>
                          <span>San Francisco</span>
                        </div>
                      </div>
                    </div>
                    <div class=card-text>
                      <p>Designed and implemented a multimodal self-supervised framework for prostate cancer long-term
                        outcome prediction.</p>
                      <p>
                      <figure
                        id=figure-the-multimodal-architecture-is-composed-of-two-parts-a-stack-to-parse-a-variable-number-of-digital-histopathology-slides-and-another-stack-to-merge-the-resultant-features-and-predict-binary-long-term-outcomes>
                        <div class="d-flex justify-content-center">
                          <div class=w-100><img src=./publication/prostate_multimodal_oncology/featured.jpeg
                              alt="screen reader text" loading=lazy data-zoomable></div>
                        </div>
                        <figcaption>The multimodal architecture is composed of two parts: a stack to parse a variable
                          number of digital histopathology slides and another stack to merge the resultant features and
                          predict binary long-term outcomes.</figcaption>
                      </figure>
                      </p>
                      <p><a href=https://www.nature.com/articles/s41746-022-00613-w target=_blank rel=noopener>Project
                          Link</a></p>
                    </div>
                  </div>
                </div>
              </div>
            </div>

            <div class="row experience">
              <div class="col-auto text-center flex-column d-none d-sm-flex">
                <div class="row h-50">
                  <div class="col border-right">&nbsp;</div>
                  <div class=col>&nbsp;</div>
                </div>
                <div class=m-2><span class="badge badge-pill border">&nbsp;</span></div>
                <div class="row h-50">
                  <div class="col border-right">&nbsp;</div>
                  <div class=col>&nbsp;</div>
                </div>
              </div>
              <div class="col py-2">
                <div class=card>
                  <div class=card-body>
                    <div class="d-flex align-content-start">
                      <div class="mr-2 mb-2"><a href=https://chanzuckerberg.com/ target=_blank rel=noopener><img
                            src=/media/icons/brands/org-czi.svg width=56px height=56px
                            alt="Chan Zuckerberg Initiative (CZI)" loading=lazy></a></div>
                      <div>
                        <div class="section-subheading card-title exp-title text-muted my-0">Computational Biology
                          Summer Intern</div>
                        <div class="section-subheading card-title exp-company text-muted my-0"><a
                            href=https://chanzuckerberg.com/ target=_blank rel=noopener>Chan Zuckerberg Initiative
                            (CZI)</a></div>
                        <div class="text-muted exp-meta">June 2019 â€“
                          September 2019
                          <span class=middot-divider></span>
                          <span>Redwood City</span>
                        </div>
                      </div>
                    </div>
                    <div class=card-text>
                      <p>Created Segmentify, an interactive and general-purpose cell segmentation plugin for the image
                        viewer Napari</p>
                      <p>
                      <figure
                        id=figure-in-the-example-above-the-user-is-using-segmentify-to-segment-out-the-nucleus-cytoplasm-and-the-background-for-all-the-cells-in-the-image-the-trained-classifier-is-used-to-predict-the-label-for-all-the-remaining-unlabeled-pixels-and-the-segmentation-output-is-displayed-at-the-segmentation-labels-layer>
                        <div class="d-flex justify-content-center">
                          <div class=w-100><img
                              src=https://raw.githubusercontent.com/transformify-plugins/segmentify/master/figs/segmentify.gif
                              alt="screen reader text" loading=lazy data-zoomable></div>
                        </div>
                        <figcaption>In the example above, the user is using segmentify to segment out the nucleus,
                          cytoplasm and the background for all the cells in the image. The trained classifier is used to
                          predict the label for all the remaining unlabeled pixels, and the segmentation output is
                          displayed at the segmentation labels layer.</figcaption>
                      </figure>
                      </p>
                      <p><a href=https://github.com/transformify-plugins/segmentify target=_blank rel=noopener>Project
                          Link</a></p>
                    </div>
                  </div>
                </div>
              </div>
            </div>

            <div class="row experience">
              <div class="col-auto text-center flex-column d-none d-sm-flex">
                <div class="row h-50">
                  <div class="col border-right">&nbsp;</div>
                  <div class=col>&nbsp;</div>
                </div>
                <div class=m-2><span class="badge badge-pill border">&nbsp;</span></div>
                <div class="row h-50">
                  <div class=col>&nbsp;</div>
                  <div class=col>&nbsp;</div>
                </div>
              </div>
              <div class="col py-2">
                <div class=card>
                  <div class=card-body>
                    <div class="d-flex align-content-start">
                      <div class="mr-2 mb-2"><a href=https://www.sdsc.edu/ target=_blank rel=noopener><img
                            src=/media/icons/brands/org-sdsc.svg width=56px height=56px
                            alt="San Diego Supercomputer Center" loading=lazy></a></div>
                      <div>
                        <div class="section-subheading card-title exp-title text-muted my-0">Research Programmer</div>
                        <div class="section-subheading card-title exp-company text-muted my-0"><a
                            href=https://www.sdsc.edu/ target=_blank rel=noopener>San Diego Supercomputer Center</a>
                        </div>
                        <div class="text-muted exp-meta">March 2015 â€“
                          December 2016
                          <span class=middot-divider></span>
                          <span>San Diego</span>
                        </div>
                      </div>
                    </div>
                    <div class=card-text>
                      <p>Developed mmtf-pyspark, a python package that parallelizes analysis and mining of protein data
                        using Apache-Spark</p>
                      <p>
                      <figure id=figure-visualization-of-protein-dna-complex-using-mmtf-pyspark>
                        <div class="d-flex justify-content-center">
                          <div class=w-100><img
                              src=https://mmtf-pyspark.readthedocs.io/en/latest/_images/ProteinDnaComplex.png
                              alt="screen reader text" loading=lazy data-zoomable></div>
                        </div>
                        <figcaption>Visualization of Protein-DNA complex using MMTF-PySpark.</figcaption>
                      </figure>
                      </p>
                      <p><a href=https://github.com/sbl-sdsc/mmtf-pyspark target=_blank rel=noopener>Project Link</a>
                      </p>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>


    <section id=photos class="home-section wg-markdown">
      <div class=home-section-bg></div>
      <div class=container>
        <div class="row justify-content-center">
          <div class="section-heading col-12 mb-3 text-center">
            <h1 class=mb-0>Amateur Photography</h1>
          </div>
          <div class=col-12>
            <div class=gallery-grid>
              <div class="gallery-item gallery-item--medium"><a data-fancybox=gallery-demo
                  href=/media/albums/demo/-B3A1944.jpg><img
                    src=/media/albums/demo/-B3A1944_hu1e5040d05941b7da612fad3b1aec666d_2003007_750x750_fit_q75_h2_lanczos.webp
                    loading=lazy alt=-B3A1944.jpg width=750 height=500></a></div>
              <div class="gallery-item gallery-item--medium"><a data-fancybox=gallery-demo
                  href=/media/albums/demo/-B3A7969.jpg><img
                    src=/media/albums/demo/-B3A7969_hu1992682bd1aca7c30460a0950270ee84_2700756_750x750_fit_q75_h2_lanczos.webp
                    loading=lazy alt=-B3A7969.jpg width=750 height=500></a></div>
              <div class="gallery-item gallery-item--medium"><a data-fancybox=gallery-demo
                  href=/media/albums/demo/-IMG-7432.jpg><img
                    src=/media/albums/demo/-IMG-7432_huefd3b67b5306ba0f1392bddc338f8419_1355864_750x750_fit_q75_h2_lanczos.webp
                    loading=lazy alt=-IMG-7432.jpg width=750 height=500></a></div>
              <div class="gallery-item gallery-item--medium"><a data-fancybox=gallery-demo
                  href=/media/albums/demo/B28624D3-3423-4D40-87B0-C162E7F17AE3.jpg><img
                    src=/media/albums/demo/B28624D3-3423-4D40-87B0-C162E7F17AE3_hu66f0ee6f4771a2fa594d7b3838d6a1ae_770917_750x750_fit_q75_h2_lanczos.webp
                    loading=lazy alt=B28624D3-3423-4D40-87B0-C162E7F17AE3.jpg width=422 height=750></a></div>
              <div class="gallery-item gallery-item--medium"><a data-fancybox=gallery-demo
                  href=/media/albums/demo/IMG-0213.jpg><img
                    src=/media/albums/demo/IMG-0213_hu41dc51d4cb1843c7dbe60b29acdd6e8f_6006845_750x750_fit_q75_h2_lanczos.webp
                    loading=lazy alt=IMG-0213.jpg width=563 height=750></a></div>
              <div class="gallery-item gallery-item--medium"><a data-fancybox=gallery-demo
                  href=/media/albums/demo/IMG-0315.JPG><img
                    src=/media/albums/demo/IMG-0315_hu59b63af5c6827743cf8434b24fdfb469_1135871_750x750_fit_q75_h2_lanczos.webp
                    loading=lazy alt=IMG-0315.JPG width=563 height=750></a></div>
              <div class="gallery-item gallery-item--medium"><a data-fancybox=gallery-demo
                  href=/media/albums/demo/IMG-0323.jpg><img
                    src=/media/albums/demo/IMG-0323_hua5ac560a90dd55d0edf2e88325d832ce_2082913_750x750_fit_q75_h2_lanczos.webp
                    loading=lazy alt=IMG-0323.jpg width=563 height=750></a></div>
              <div class="gallery-item gallery-item--medium"><a data-fancybox=gallery-demo
                  href=/media/albums/demo/IMG-0917%20%281%29.jpg><img
                    src=/media/albums/demo/IMG-0917%20%281%29_hubc01cdfa2006104f5410f939b5140984_558096_750x750_fit_q75_h2_lanczos.webp
                    loading=lazy alt="IMG-0917 (1).jpg" width=569 height=750></a></div>
              <div class="gallery-item gallery-item--medium"><a data-fancybox=gallery-demo
                  href=/media/albums/demo/IMG-3482.jpg><img
                    src=/media/albums/demo/IMG-3482_hu89429714d54a944b3406ccbba9587ef8_93337_750x750_fit_q75_h2_lanczos.webp
                    loading=lazy alt=IMG-3482.jpg width=750 height=500></a></div>
              <div class="gallery-item gallery-item--medium"><a data-fancybox=gallery-demo
                  href=/media/albums/demo/IMG-3928.JPG><img
                    src=/media/albums/demo/IMG-3928_hu54db6c8ec03dc71b21d078d3ea9472ea_166588_750x750_fit_q75_h2_lanczos.webp
                    loading=lazy alt=IMG-3928.JPG width=500 height=750></a></div>
              <div class="gallery-item gallery-item--medium"><a data-fancybox=gallery-demo
                  href=/media/albums/demo/IMG-4038.JPG><img
                    src=/media/albums/demo/IMG-4038_hu81078be0c19a7a44323bee18a0c011d8_502361_750x750_fit_q75_h2_lanczos.webp
                    loading=lazy alt=IMG-4038.JPG width=750 height=500></a></div>
              <div class="gallery-item gallery-item--medium"><a data-fancybox=gallery-demo
                  href=/media/albums/demo/IMG-7175.JPG><img
                    src=/media/albums/demo/IMG-7175_hu1104aa2863da19e197ce36a76b267dd5_1169097_750x750_fit_q75_h2_lanczos.webp
                    loading=lazy alt=IMG-7175.JPG width=500 height=750></a></div>
            </div>
          </div>
        </div>
      </div>
    </section>
  </div>
  <div class=page-footer>
    <div class=container>
      <footer class=site-footer>
        <p class="powered-by copyright-license-text">Â© 2023 Me. This work is licensed under <a
            href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank>CC BY NC ND
            4.0</a></p>
        <p class="powered-by footer-license-icons"><a href=https://creativecommons.org/licenses/by-nc-nd/4.0
            rel="noopener noreferrer" target=_blank aria-label="Creative Commons"><i
              class="fab fa-creative-commons fa-2x" aria-hidden=true></i>
            <i class="fab fa-creative-commons-by fa-2x" aria-hidden=true></i>
            <i class="fab fa-creative-commons-nc fa-2x" aria-hidden=true></i>
            <i class="fab fa-creative-commons-nd fa-2x" aria-hidden=true></i></a></p>
        <p class=powered-by>Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank
            rel=noopener>Wowchemy</a> â€” the free, <a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank
            rel=noopener>open source</a> website builder that empowers creators.</p>
      </footer>
    </div>
  </div>
  <script src=/js/vendor-bundle.min.d26509351aa0ff874abbee824e982e9b.js></script>
  <script id=search-hit-fuse-template type=text/x-template>
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script>
  <script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js
    integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw=="
    crossorigin=anonymous></script>
  <script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js
    integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg=="
    crossorigin=anonymous></script>
  <script id=page-data type=application/json>{"use_headroom":false}</script>
  <script src=/en/js/wowchemy.min.e8ee06ba8371980ffde659871dd593b0.js></script>
  <div id=modal class="modal fade" role=dialog>
    <div class=modal-dialog>
      <div class=modal-content>
        <div class=modal-header>
          <h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
            <span aria-hidden=true>&#215;</span></button>
        </div>
        <div class=modal-body>
          <pre><code></code></pre>
        </div>
        <div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i
              class="fas fa-copy"></i> Copy</a>
          <a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i>
            Download</a>
          <div id=modal-error></div>
        </div>
      </div>
    </div>
  </div>
  <script src=/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js type=module></script>
</body>

</html>